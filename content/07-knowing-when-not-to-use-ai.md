# Knowing When Not to Use AI

The most expert thing an expert might do in the near future is know when *not* to use the tool.

This is different from "supervising" AI or "validating" its output.

It's knowing that for this particular problem, in this particular context, the right move is to think slowly without assistance.

There is a certain kind of thinking that only happens when you are struggling with a blank page.

There is a certain kind of attention that only emerges when you resist the pull toward efficient assistance.

There is a certain kind of discovery that only occurs in the friction of doing it yourself.

The skill isn't just "when to delegate to AI" but "when to protect a space from AI entirely."

Some problems require marination. Some insights only come from sustained, unassisted struggle. Some forms of understanding require that you *not* know the answer until you've worked toward it yourself.

This discernment is non-trivial to teach.

It requires:
- Experience with both modes (assisted and unassisted)
- Metacognitive awareness of how thinking changes in each mode
- Confidence that slow, unassisted work can produce results that fast, assisted work cannot

It also requires institutional protection: spaces where AI assistance is deliberately absent, not because we're afraid of cheating, but because we're protecting a mode of cognition.

The "when not to use AI" question is ultimately a question about what kind of thinker you want to become.

The university might be one of the few places left where that question is still taken seriously.
